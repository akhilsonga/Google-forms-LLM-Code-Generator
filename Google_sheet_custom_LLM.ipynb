{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "133aab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools user want to use:  ['Calculator', 'Internet Search', 'Python Executor']\n",
      "Calculator\n",
      "Internet Search\n",
      "Python Executor\n",
      ">>which Indian IPL team won today match \n",
      "\n",
      "\n",
      "\n",
      "Prompt: \n",
      "            To use a tool you should write 'Action:' and tool name you want to use, but if user ask any general query you can answer without any tools or actions.\n",
      "            \n",
      "            Here are the tools you can use to calculate or collect information from the internet or python code to execute or voice reply, If you need: \n",
      "Calculator[<Your expression to calculate>], Search[<Key words to search in internet>], Python[```python <Your python code here> ```]\n",
      "            \n",
      "            Example of Using the tools:\n",
      "            Action: Calculator[12*34-57], Action: Search[All the influencers of HELIOS Company], Action: Python[```python\n",
      "a = 12\n",
      "b = 10\n",
      "c = a+b\n",
      "print(c) ```]\n",
      "            \n",
      "\n",
      "            User: which Indian IPL team won today match \n",
      "LLM_OUTPIT*************\n",
      "Action Tools using:  ['Search[which Indian IPL team won today match]']\n",
      "Query sending to tools handler which Indian IPL team won today match \n",
      "which Indian IPL team won today match\n",
      "Duck Duck Go : Get the latest scores on the go. Find the latest content, including match highlights, press conferences and recap all at your fingertips by downloading the official IPL app. Available on both App store and Playstore. Download here for free. IPL 2024 | Official site for real-time cricket updates, scores, teams, and exclusive content. MUMBAI (AP) â€” Romario Shepherd smashed 32 in the last over of his team's innings as five-time champion Mumbai Indians secured its first win in the Indian Premier League with a 29-run victory over Delhi Capitals on Sunday. In the day's second game, Lucknow Super Giants beat Gujarat Titans by 33 runs to win its third straight match. MI vs DC IPL 2024 Highlights: Mumbai Indians registered their first win this season as they defeated Delhi Capitals by 29 runs. The hosts posted a 234 for 5 against Delhi Capitals. Rohit Sharma provided a blazing start, scoring 49 off 27 balls and added 80 for the opening stand in just 7 overs with Ishan Kishan (42 off 23 balls), while Hardik Pandya (39 off 33 balls) and Tim David (45 not out ... 12:35 (IST) Apr 07. Eyes on MI vs DC first. Action kicks off in the aftrenoon with match number 20 of the tournament between Mumbai Indians and Delhi Capitals at the Wankhede Stadium in Mumbai, as ... LSG vs GT, IPL 2024 Highlights: Lucknow Super Giants were clinical while registering a 33-run win over Gujarat Titans in their IPL 2024 match at Ekana Cricket Stadium on Sunday. The Gujarat side ... IPL 2024, Delhi (DC) vs Chennai (CSK) As it happened: Despite a vintage MS Dhoni show during the death overs of the game, it was Delhi who grabbed their first win of the season with their victory over Chennai by 20 runs. A brilliant batting performance by David Warner with his 52(35) knock and Rishabh Pant's nostalgic 51(32) played a pivotal role in Delhi's win. Mukesh Kumar was the best ... He stopped Punjab Kings in their tracks, blew RCB away, bowled the fastest ball of the season (156.7 kph), and became the first to win Player of the Match awards in his first two IPL matches. Get the latest scores on the go. Find the latest content, including match highlights, press conferences and recap all at your fingertips by downloading the official IPL app. Available on both App store and Playstore. Download here for free. IPL 2024 | Official site for real-time cricket updates, scores, teams, and exclusive content. 15 October 2021 Cricket 255. Faf du Plessis hit a match-winning 86 off 59 balls. Indian Premier League final, Dubai. Chennai Super Kings 192-3 (20 overs): Du Plessis 86 (59); Moeen 37no (20 ... Sunrisers Hyderabad stunned Mumbai Indians with the highest total in the Indian Premier League; Sunrisers 277-3 was fourth highest in mens T20 history; watch the 2024 Indian Premier League season ... Sanju Samson won the toss and the Royals opted to bowl as they are looking for their 4th straight win and a place at the top of the IPL 2024 points table. On the other hand, RCB will be looking to arrest their slide after having lost two on the bounce. The Battle Royale is underway at the Sawai Mansingh Stadium. RR vs RCB, IPL 2024 Live Scorecard Hardik Pandya and Rishabh Pant will be the point of focus on Sunday but for contrasting reasons. MI vs DC Live Score, IPL 2024: Mumbai have made a brisk start to the innings with Rohit and Kishan hitting boundaries early on in their innings. DC had won the toss and opted to bowl first in Mumbai as the Wankhede track does seem like a belter at ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The provided reference does not contain the information about which Indian IPL team won today's match. Therefore, I cannot answer your question.\n"
     ]
    }
   ],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "import re\n",
    "import os\n",
    "import pyttsx3\n",
    "\n",
    "from groq import Groq\n",
    "if os.getenv(\"GROQ_API_KEY\") is None:\n",
    "    os.environ[\"GROQ_API_KEY\"] = \n",
    "\n",
    "    \n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "import os\n",
    "\n",
    "import whisper\n",
    "from langdetect import detect\n",
    "from pytube import YouTube\n",
    "\n",
    "\n",
    "import tempfile\n",
    "\n",
    "#_________________________________________________________________________________________________________________\n",
    "\n",
    "#Youtube Search Video RAG with Vector DB\n",
    "\n",
    "def startfile(fn):\n",
    "    os.system('open %s' % fn)\n",
    "\n",
    "def create_and_open_txt(text, filename):\n",
    "    # Create and write the text to a txt file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(text)\n",
    "    startfile(filename)\n",
    "\n",
    "\n",
    "def delete_audio_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"Audio file {file_path} deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting audio file: {e}\")\n",
    "\n",
    "    \n",
    "def youtube_audio_text(url, path):\n",
    "    yt = YouTube(url)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    \n",
    "    output_path = path \n",
    "    filename = \"audio.mp3\"\n",
    "    audio_stream.download(output_path=output_path, filename=filename)\n",
    "\n",
    "    print(f\"Audio downloaded to {output_path}\\{filename}\")\n",
    "\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(path + \"\\\\audio.mp3\")\n",
    "    transcribed_text = result[\"text\"]\n",
    "    #print(transcribed_text)\n",
    "\n",
    "    # language = detect(transcribed_text)\n",
    "    # print(f\"Detected language: {language}\")\n",
    "    delete_audio_file(path + \"\\\\audio.mp3\")\n",
    "    \n",
    "    create_and_open_txt(transcribed_text, path + \"\\\\output_Text.txt\")\n",
    "\n",
    "\n",
    "def Youtube_RAG(model, path):\n",
    "    llm = Ollama(model=\"mistral\", request_timeout=30.0)\n",
    "\n",
    "    #inp = input(\"enter 1 - Hugging Face Embedding \\n2 - OpenAI Embedding\")\n",
    "    inp = 1\n",
    "    if inp == 1:\n",
    "        #\n",
    "        Settings.embed_model = HuggingFaceEmbedding(model_name=\"flax-sentence-embeddings/all_datasets_v4_MiniLM-L6\")\n",
    "\n",
    "\n",
    "    #Settings.llm = Ollama(model=\"mistral\", request_timeout=200.0)\n",
    "    Settings.llm = Ollama(model=model, request_timeout=200.0)\n",
    "    \n",
    "    documents = SimpleDirectoryReader(path).load_data()\n",
    "    sen_split=TokenTextSplitter()\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[sen_split]\n",
    "    )\n",
    "    nodes=pipeline.run(show_progress=True,documents=documents, in_place=True)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, transformations=[sen_split]\n",
    "    )\n",
    "    index.storage_context.persist(persist_dir=\"./indexDB\")\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./indexDB\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(\"Summary of the Document\")\n",
    "    print(response)\n",
    "    return response\n",
    "    \n",
    "#     while True:\n",
    "#         #\n",
    "#         user_input = input(\"Enter 'stop' to end: \")\n",
    "#         if user_input.lower() == 'stop':\n",
    "#             print(\"Stopping the loop.\")\n",
    "#             break\n",
    "#         else:\n",
    "#             response = query_engine.query(user_input)\n",
    "#             print()\n",
    "#             print(response)\n",
    "        \n",
    "\n",
    "def youtube(url):\n",
    "    path = tempfile.mkdtemp()\n",
    "    youtube_audio_text(url, path)\n",
    "    #model_id = input(\"Enter the model you want to use: 1 - Mistral, 2- Codellama 13B, 3 - llava\")\n",
    "    model_id = 1\n",
    "    if model_id == 1:\n",
    "        response = Youtube_RAG(\"mistral\", path)\n",
    "    elif model_id == 2:\n",
    "        response = Youtube_RAG(\"codellama:13b\", path)\n",
    "#     elif model_id == 3:\n",
    "#         Youtube_RAG(\"codellama:13b\")\n",
    "    return response\n",
    "\n",
    "#_________________________________________________________________________________________________________________\n",
    "    \n",
    "    \n",
    "#Not using Groq Max Tokens Completed for Today\n",
    "def O_LLM_GroQ(query):\n",
    "    print(\"Groq!\")\n",
    "    client = Groq(\n",
    "        api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "        #model=\"gemma-7b-it\",\n",
    "        temperature = 0,\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response\n",
    "\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "#Gemini 1.0 pro, good not great need to test on 1.5 pro in google hackathon\n",
    "def O_LLM_gemini(query):\n",
    "    Gemini_API = \n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    genai.configure(api_key=Gemini_API)\n",
    "    response = model.generate_content(query)\n",
    "    resp = response.text\n",
    "   # print(response.text)\n",
    "    return resp\n",
    "\n",
    "def extract_thoughts_actions_output(text):\n",
    "    thoughts = []\n",
    "    actions = []\n",
    "    outputs = []\n",
    "\n",
    "    thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "    action_pattern = r'Action \\d+:\\s*(.*)'\n",
    "    output_pattern = r'Output \\d+:\\s*(.*)'\n",
    "\n",
    "    # Extract Thoughts, Actions, and Output\n",
    "    thoughts = re.findall(thought_pattern, text)\n",
    "    actions = re.findall(action_pattern, text)\n",
    "    outputs = re.findall(output_pattern, text)\n",
    "\n",
    "    return thoughts, actions, outputs\n",
    "\n",
    "def extract_info(texts):\n",
    "    \"\"\"\n",
    "    This function extracts tools and inputs from a list of text strings.\n",
    "\n",
    "    Args:\n",
    "      texts: A list of strings containing instructions with tools and inputs in brackets.\n",
    "\n",
    "    Returns:\n",
    "      A dictionary where keys are tools (e.g., \"Search\", \"Summarize\", \"Calculate\") \n",
    "      and values are corresponding inputs (e.g., \"funding received by Mistral Ai from investors\").\n",
    "    \"\"\"\n",
    "    tools = {}\n",
    "    for text in texts:\n",
    "        # Extract tool using regular expression\n",
    "        tool = re.findall(r'^\\w+', text)[0]\n",
    "\n",
    "        # Extract input using regular expression\n",
    "        inp = re.findall(r'\\[(.*?)\\]', text)[0]\n",
    "\n",
    "        # Add tool and input to the dictionary\n",
    "        tools[tool] = inp\n",
    "    return tools\n",
    "\n",
    "\n",
    "\n",
    "def duck_go(Keyword):\n",
    "    print(Keyword)\n",
    "    results = DDGS().text(Keyword, max_results=12)\n",
    "    bodies = [item['body'] for item in results]\n",
    "    paragraph = ' '.join(bodies)\n",
    "    return paragraph\n",
    "\n",
    "def Calculate(expression):\n",
    "    print(f\"Calculating: {expression}\")\n",
    "\n",
    "    \n",
    "import subprocess\n",
    "\n",
    "def execute_python(code):\n",
    "    #print(\"Code recieved for execution Terminal: \",code)\n",
    "    result = subprocess.run([\"python\", \"-c\", code], capture_output=True, text=True)\n",
    "    err = 0\n",
    "    # Check if there's an error\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error Found\")\n",
    "        err = 1\n",
    "        return result.stderr, err\n",
    "    else:\n",
    "        \n",
    "        output = result.stdout\n",
    "        return output, err\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def extract_text(input_string, option):\n",
    "    if option == 1:\n",
    "        pattern = r'\\```python(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        pattern = r'\\```(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def check_substring(main_string, substring):\n",
    "\n",
    "    if substring.lower() in main_string.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#------------------------------------------------------------------------------------------------\n",
    "Error_Counter = 0\n",
    "\n",
    "def code_processing(answer):\n",
    "    #answer = O_LLM(query)\n",
    "    print(\"Preprocessing code for execution\")\n",
    "    main_string = answer\n",
    "    substring = \"```python\"\n",
    "    substring_sub = \"```\"\n",
    "    print(\"\\n\\n\")\n",
    "    if check_substring(main_string, substring_sub):\n",
    "        #print(\"```, FOUND PREPROCESSING... \")\n",
    "        \n",
    "        if check_substring(main_string, substring):\n",
    "            #print(\"```python, FOUND PREPROCESSING... \")\n",
    "            input_string =  answer\n",
    "            extracted_text = extract_text(input_string, 1)\n",
    "            \n",
    "            if extracted_text:\n",
    "                answer = extracted_text\n",
    "                #print(\"Extracted Text: \\n\", answer)\n",
    "                code = answer\n",
    "            else:\n",
    "                #print(\"No text found between ``` and ```.\")\n",
    "                code = answer\n",
    "        else:\n",
    "            print(\"\")\n",
    "            if check_substring(main_string, substring_sub):\n",
    "                print(\"```python, FOUND PREPROCESSING... \")\n",
    "                input_string =  answer\n",
    "                extracted_text = extract_text(input_string, 0)\n",
    "\n",
    "                if extracted_text:\n",
    "                    answer = extracted_text\n",
    "                    #print(\"Extracted Text: \\n\", answer)\n",
    "                    code = answer\n",
    "                else:\n",
    "                    print(\"No text found between ``` and ```.\")\n",
    "                    code = answer\n",
    "            \n",
    "    else:\n",
    "        print(\"```python ,NOT FOUND\")\n",
    "        code = answer\n",
    "    print(\"Code Extracted: \",code)\n",
    "    code_to_execute = code    \n",
    "    result, err = execute_python(code_to_execute)\n",
    "    if err == 0:\n",
    "        print(\"Returning Result to Prompt: \", result)\n",
    "        Error_Counter = 0\n",
    "        return result\n",
    "    else:\n",
    "        Code_error_recur(code_to_execute, result)\n",
    "\n",
    "        \n",
    "\n",
    "def Code_error_recur(code_to_execute, result):\n",
    "    Error_Counter = Error_Counter + 1\n",
    "    Error_query = \"Code: \" + code_to_execute + \"\\n Error: \" + result + \"\\n Dont add any comments and always write code under these tags '```python' and '```' \" \n",
    "    resp = O_LLM(Error_query)\n",
    "    code_processing(resp)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def calculate(expression):\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "    \n",
    "\n",
    "def Voice(voice_response):\n",
    "    text = voice_response\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 190)    # Speed percent (can go over 100)\n",
    "    engine.setProperty('volume', 0.9)  # Volume 0-1\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "    return \"Speaking completed\"\n",
    "    \n",
    "    \n",
    "#Afterwards Update match with elif\n",
    "def handle_request(data, thought, model):\n",
    "    #\n",
    "    if \"Search\" in data:\n",
    "        output = duck_go(data[\"Search\"])\n",
    "        param = data[\"Search\"]\n",
    "#         print(\"In DuckDuckGo Search Question:\",thought)\n",
    "        print(\"Duck Duck Go :\",output)\n",
    "        print(\"\\n\\n\\n\")\n",
    "        prompt = f\"consider the text based on the reference, if you found no connection between the Question and Reference, find the most relevant answer for the question \\n Question: {thought}\\n\\n\\n Reference: {output}\"\n",
    "        output = Model_selector(model, prompt)\n",
    "        return output\n",
    "    elif \"Calculate\" in data:\n",
    "        output = Calculate(data[\"Calculate\"])\n",
    "        return output\n",
    "    elif \"Python\" in data:\n",
    "        output = code_processing(data[\"Python\"])\n",
    "        return output\n",
    "    elif \"Voice\" in data:\n",
    "        output = Voice(data[\"Voice\"])\n",
    "        return output\n",
    "    elif \"Youtube\" in data:\n",
    "        output = youtube(data[\"Youtube\"])\n",
    "        return output\n",
    "    else:\n",
    "        print(\"Invalid key. Please use 'Search' or 'Calculate'\")\n",
    "\n",
    "        \n",
    "def convert_list_to_dict(data):\n",
    "    result = {}\n",
    "    for item in data:\n",
    "        try:\n",
    "            key, value = item.split('[', 1)\n",
    "            value = value.rsplit(']', 1)[0].strip()  # Get text from beginning to last ']'\n",
    "            if value:  # Check if value is not empty (null)\n",
    "                result[key.strip()] = value\n",
    "        except ValueError:\n",
    "            continue  # Skip to the next iteration if splitting fails\n",
    "    return result\n",
    "#------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "def extract_thoughts_actions_output(text):\n",
    "    thoughts = []\n",
    "    actions = []\n",
    "    outputs = []\n",
    "\n",
    "    thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "    action_pattern = r'Action \\d+:\\s*([\\s\\S]*?)(?=(?:Thought \\d+|$))'\n",
    "    output_pattern = r'output:\\s*(.*)'\n",
    "\n",
    "    # Extract Thoughts, Actions, and Output\n",
    "    thoughts = re.findall(thought_pattern, text, re.IGNORECASE)\n",
    "    action_matches = re.findall(action_pattern, text, re.IGNORECASE)\n",
    "    actions = ['\\n'.join(action.strip().split('\\n')) for action in action_matches]\n",
    "    outputs = re.findall(output_pattern, text, re.IGNORECASE)\n",
    "\n",
    "    return thoughts, actions, outputs\n",
    "\n",
    "\n",
    "def extract_actions(text):\n",
    "    pattern = r'[Aa]ction(?:[:\\s\\d]+)?\\s*([^\\[\\]]+\\[[^\\[\\]]+\\])'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def Text_to_list(text):\n",
    "    names = text.split(',')\n",
    "    return names\n",
    "\n",
    "\n",
    "def Model_selector(data, prompt):\n",
    "    if \"gemini\" in data:\n",
    "        output = O_LLM_gemini(prompt)\n",
    "        return output\n",
    "    elif \"mixtral\" in data:\n",
    "        output = O_LLM_GroQ(prompt)\n",
    "        return output\n",
    "    elif \"openai\" in data:\n",
    "        output = O_LLM_openai(prompt)\n",
    "        return output\n",
    "    elif \"mistral\" in data:\n",
    "        output = O_LLM_mistral(prompt)\n",
    "        return output\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "    \n",
    "def extract_actions(text):\n",
    "    pattern = r'[Aa]ction(?:[:\\s\\d]+)?\\s*([^\\[\\]]+\\[[^\\[\\]]+\\])'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n",
    "\n",
    "def contains_action(text):\n",
    "    pattern = re.compile(r'\\b(?:action|Action)\\s*:')\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "\n",
    "def between_LLM_and_user(out,inp, model):\n",
    "\n",
    "    if contains_action(out):\n",
    "        #\n",
    "\n",
    "        actions_list = extract_actions(out)\n",
    "        print(\"Action Tools using: \",actions_list)\n",
    "        actions_tools_dic = convert_list_to_dict(actions_list)\n",
    "        main_dict = actions_tools_dic\n",
    "        last_key_value = {list(main_dict.keys())[-1]: main_dict[list(main_dict.keys())[-1]]}\n",
    "        print(\"Query sending to tools handler\",inp)\n",
    "        ans = handle_request(last_key_value, inp , model)\n",
    "        return ans\n",
    "    else:\n",
    "#         print(\"Actions not found showing output\")\n",
    "        return out\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def Tools_selector(data):\n",
    "    calculator_tool_prompt = \"Calculator[<Your expression to calculate>]\"\n",
    "    search_tool_prompt = \"Search[<Key words to search in internet>]\"\n",
    "    python_tool_prompt = \"Python[```python <Your python code here> ```]\"\n",
    "    voice_tool_prompt = \"Voice[<Your text>]\"\n",
    "    \n",
    "    if \"Calculator\" in data:\n",
    "        output = f\"{calculator_tool_prompt}\"\n",
    "        return output\n",
    "    elif \"Internet Search\" in data:\n",
    "        output = f\"{search_tool_prompt}\"\n",
    "        return output\n",
    "    elif \"Python Executor\" in data:\n",
    "        output = f\"{python_tool_prompt}\"\n",
    "        return output\n",
    "    elif \"Voice\" in data:\n",
    "        output = f\"{voice_tool_prompt}\"\n",
    "        return output\n",
    "#     elif \"Youtube\" in data:\n",
    "#         output = f\"{}\"\n",
    "#         return output\n",
    "#     elif \"email\" in data:\n",
    "#         output = f\"{}\"\n",
    "#         return output\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "def Tools_example_prompt_selector(data):\n",
    "    example_calculator_tool_prompt = \"Action: Calculator[12*34-57]\"\n",
    "    example_search_tool_prompt = \"Action: Search[All the influencers of HELIOS Company]\"\n",
    "    example_python_tool_prompt = \"Action: Python[```python\\na = 12\\nb = 10\\nc = a+b\\nprint(c) ```]\"\n",
    "    example_voice_tool_prompt = \"Action: Voice[Hello, I am a Bot, can you hear me]\"\n",
    "    \n",
    "    if \"Calculator\" in data:\n",
    "        output = f\"{example_calculator_tool_prompt}\"\n",
    "        return output\n",
    "    elif \"Internet Search\" in data:\n",
    "        output = f\"{example_search_tool_prompt}\"\n",
    "        return output\n",
    "    elif \"Python Executor\" in data:\n",
    "        output = f\"{example_python_tool_prompt}\"\n",
    "        return output\n",
    "    elif \"Voice\" in data:\n",
    "        output = f\"{example_voice_tool_prompt}\"\n",
    "        return output\n",
    "#     elif \"Youtube\" in data:\n",
    "#         output = f\"{}\"\n",
    "#         return output\n",
    "#     elif \"email\" in data:\n",
    "#         output = f\"{}\"\n",
    "#         return output\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "def list_to_string(my_list):\n",
    "    result_string = \", \".join(my_list) \n",
    "    return result_string\n",
    "\n",
    "def LLM(model, prompt, inp):\n",
    "    out = Model_selector(model, prompt)\n",
    "    out = between_LLM_and_user(out, inp, model)\n",
    "    return out\n",
    "#------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "def Main():\n",
    "    model  = \"gemini\"\n",
    "    tools = \"Calculator,Internet Search,Python Executor\"\n",
    "    Rag = \"None\"\n",
    "\n",
    "#     prompt = \"Hello, who are you\"\n",
    "\n",
    "\n",
    "    tools_list = Text_to_list(tools)\n",
    "    print(\"Tools user want to use: \",tools_list)\n",
    "\n",
    "\n",
    "    prompt_tools_list = []\n",
    "    prompt_tools_example_list = []\n",
    "    for i in tools_list:\n",
    "        print(i)\n",
    "        tool = Tools_selector(i)\n",
    "        prompt_tools_list.append(tool)\n",
    "        tool_example = Tools_example_prompt_selector(i)\n",
    "        prompt_tools_example_list.append(tool_example)\n",
    "\n",
    "    if tools_list:\n",
    "        prompt_tools_list_text = list_to_string(prompt_tools_list)\n",
    "        prompt_tools_example_text = list_to_string(prompt_tools_example_list)\n",
    "        \n",
    "        prompt_part_one = f\"\"\"\n",
    "            Here are the tools you can use to calculate or collect information from the internet or python code to execute or voice reply, If you need: \\n{prompt_tools_list_text}\n",
    "            \n",
    "            Example of Using the tools:\n",
    "            {prompt_tools_example_text}\n",
    "            \"\"\"\n",
    "        inp = input(\">>\")\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        prompt_part_two = f\"\"\"\n",
    "            To use a tool you should write 'Action:' and tool name you want to use, but if user ask any general query you can answer without any tools or actions.\n",
    "            {prompt_part_one}\n",
    "\n",
    "            User: {inp}\"\"\"\n",
    "        \n",
    "        #out = Model_selector(model, prompt_part_two)\n",
    "        print(\"Prompt:\",prompt_part_two)\n",
    "        print(\"LLM_OUTPIT*************\")\n",
    "        out = LLM(model, prompt_part_two, inp)\n",
    "        print(out)\n",
    "    else:\n",
    "        print(\"none\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  Main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705931cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341ed42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cffd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f830c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72283b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3767b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0244f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a94e36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = values[1]\n",
    "tools_gsheet = values[2]\n",
    "rag_gsheet = values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "282066af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GEMINI 1.0 PRO'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4f88f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculator, Internet Search, Python Executor'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "abfdcd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_gsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c5b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f7c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db8e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM(model, prompt, inp):\n",
    "    out = Model_selector(model, prompt)\n",
    "    out = between_LLM_and_user(out, inp, model)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Hi, what is the name of the Claus opus creator? i just want to know\n",
    "inp = input(\"Question:\")\n",
    "prompt_part_two = f\"\"\"\n",
    "To use a tool you should write Action: and tool you want to use\n",
    "{prompt_part_one}\n",
    "User: Hello how are you?\n",
    "Bot: I am doing well, thank you for asking. How can I assist you today?\n",
    "User: {inp}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt_part_two)\n",
    "\n",
    "out = Model_selector(model, prompt_part_two)\n",
    "print(out)\n",
    "out = between_LLM_and_user(out, inp, model)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90f6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def Text_to_list(text):\n",
    "    names = text.split(',')\n",
    "    return names\n",
    "\n",
    "def Model_selector(data, prompt):\n",
    "    if \"gemini\" in data:\n",
    "        output = O_LLM_gemini(prompt)\n",
    "        return output\n",
    "    elif \"mixtral\" in data:\n",
    "        output = O_LLM_mixtral(prompt)\n",
    "        return output\n",
    "    elif \"openai\" in data:\n",
    "        output = O_LLM_openai(prompt)\n",
    "        return output\n",
    "    elif \"mistral\" in data:\n",
    "        output = O_LLM_mistral(prompt)\n",
    "        return output\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "    \n",
    "def extract_actions(text):\n",
    "    pattern = r'[Aa]ction(?:[:\\s\\d]+)?\\s*([^\\[\\]]+\\[[^\\[\\]]+\\])'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n",
    "\n",
    "def contains_action(text):\n",
    "    pattern = re.compile(r'\\b(?:action|Action)\\s*:')\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "\n",
    "def between_LLM_and_user(out,inp, model):\n",
    "    if contains_action(out):\n",
    "        actions_list = extract_actions(out)\n",
    "        print(\"Action Tools using: \",actions_list)\n",
    "        actions_tools_dic = convert_list_to_dict(actions_list)\n",
    "        main_dict = actions_tools_dic\n",
    "        last_key_value = {list(main_dict.keys())[-1]: main_dict[list(main_dict.keys())[-1]]}\n",
    "        print(\"Query sending to tools handler\",inp)\n",
    "        ans = handle_request(last_key_value, inp , model)\n",
    "        return ans\n",
    "    else:\n",
    "#         print(\"Actions not found showing output\")\n",
    "        return out\n",
    "\n",
    "\n",
    "model  = \"gemini\"\n",
    "tools = \"Calculator, Internet Search, Python Executor\"\n",
    "Rag = \"None\"\n",
    "\n",
    "prompt = \"Hello, who are you\"\n",
    "out = Model_selector(model, prompt)\n",
    "print(out)\n",
    "\n",
    "tools_list = Text_to_list(tools)\n",
    "print(\"Tools user want to use: \",tools_list)\n",
    "\n",
    "calculator_tool_prompt = \"Calculator[<Your expression to calculate>]\"\n",
    "search_tool_prompt = \"Search[<Key words to search in internet>]\"\n",
    "python_tool_prompt = \"Python[```python <Your python code here> ```]\"\n",
    "voice_tool_prompt = \"Voice[<Your text>]\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5281317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445ca51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed258f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_part_one = f\"\"\"\n",
    "Here are the tools you can use to calculate or collect information from the internet or python code to execute or voice reply, If you need: \\n{tools_user_selected}\n",
    "Example of Actions:\n",
    "{tools_user_selected_example}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a022e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_part_two = f\"\"\"\n",
    "To use a tool you should write Action: and tool you want to use\n",
    "{prompt_part_one}\n",
    "User: Hello how are you?\n",
    "Bot: I am doing well, thank you for asking. How can I assist you today?\n",
    "User: {inp}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13ce07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b10965b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(my_list):\n",
    "    result_string = \", \".join(my_list) \n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a2a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tools_list_text = list_to_string(prompt_tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604174ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculator[<Your expression to calculate>], Search[<Key words to search in internet>], Python[```python <Your python code here> ```], Voice[<Your text>]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tools_list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cf1509d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3652005817.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    Phone call\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "RAG\n",
    "Phone call\n",
    "Tools: calculator, Internet_Search, Voice, Youtube, pythoncode, email\n",
    "Embedding model\n",
    "LLM Model\n",
    "Chatbot\n",
    "Prompt Template\n",
    "Knowledge graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "161a5866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Gemini, a large multi-modal model, trained by Google. I am designed to provide information and answer questions to the best of my abilities.\n",
      "Tools user want to use:  ['Calculator', ' Internet Search', ' Python Executor']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c322f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_user_selected = f\"{calculator_tool_prompt}, {search_tool_prompt}, {python_tool_prompt}, {voice_tool_prompt}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbd13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_calculator_tool_prompt = \"Action: Calculator[12*34-57]\"\n",
    "example_search_tool_prompt = \"Action: Search[All the influencers of HELIOS Company]\"\n",
    "example_python_tool_prompt = \"Action: Python[```python\\na = 12\\nb = 10\\nc = a+b\\nprint(c) ```]\"\n",
    "example_voice_tool_prompt = \"Action: Voice[Hello, I am a Bot, can you hear me]\"\n",
    "\n",
    "tools_user_selected_example = f\"{example_calculator_tool_prompt}\\n{example_search_tool_prompt}\\n{example_python_tool_prompt}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1938e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_part_one = f\"\"\"\n",
    "Here are the tools you can use to calculate or collect information from the internet or python code to execute or voice reply, If you need: \\n{tools_user_selected}\n",
    "Example of Actions:\n",
    "{tools_user_selected_example}\n",
    "\"\"\"\n",
    "print(prompt_part_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Hi, what is the name of the Claus opus creator? i just want to know\n",
    "inp = input(\"Question:\")\n",
    "prompt_part_two = f\"\"\"\n",
    "To use a tool you should write Action: and tool you want to use\n",
    "{prompt_part_one}\n",
    "User: Hello how are you?\n",
    "Bot: I am doing well, thank you for asking. How can I assist you today?\n",
    "User: {inp}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt_part_two)\n",
    "\n",
    "out = Model_selector(model, prompt_part_two)\n",
    "print(out)\n",
    "out = between_LLM_and_user(out, inp, model)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa888264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54116412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36ca96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2752d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculator[<Your expression to calculate>], Search[<Key words to search in internet>], Python[```python <Your python code here> ```], Voice[<Your text>]'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_user_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "263d13e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9ff47a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here are the tools you can use to calculate or collect information from the internet or python code to execute or voice reply, If you need: \n",
      "Calculator[<Your expression to calculate>], Search[<Key words to search in internet>], Python[```python <Your python code here> ```], Voice[<Your text>]\n",
      "Example of Actions:\n",
      "Action: Calculator[12*34-57]\n",
      "Action: Search[All the influencers of HELIOS Company]\n",
      "Action: Python[```python\n",
      "a = 12\n",
      "b = 10\n",
      "c = a+b\n",
      "print(c) ```]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_part_one = f\"\"\"\n",
    "Here are the tools you can use to calculate or collect information from the internet or python code to execute or voice reply, If you need: \\n{tools_user_selected}\n",
    "Example of Actions:\n",
    "{tools_user_selected_example}\n",
    "\"\"\"\n",
    "print(prompt_part_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "70c87b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_actions(text):\n",
    "    pattern = r'[Aa]ction(?:[:\\s\\d]+)?\\s*([^\\[\\]]+\\[[^\\[\\]]+\\])'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n",
    "def contains_action(text):\n",
    "    pattern = re.compile(r'\\b(?:action|Action)\\s*:')\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "def between_LLM_and_user(out,inp, model):\n",
    "    if contains_action(out):\n",
    "        actions_list = extract_actions(out)\n",
    "        print(\"Action Tools using: \",actions_list)\n",
    "        actions_tools_dic = convert_list_to_dict(actions_list)\n",
    "        main_dict = actions_tools_dic\n",
    "        last_key_value = {list(main_dict.keys())[-1]: main_dict[list(main_dict.keys())[-1]]}\n",
    "        print(\"Query sending to tools handler\",inp)\n",
    "        ans = handle_request(last_key_value, inp , model)\n",
    "        return ans\n",
    "    else:\n",
    "#         print(\"Actions not found showing output\")\n",
    "        return out\n",
    "\n",
    "#Hi, what is the name of the Claus opus creator? i just want to know\n",
    "inp = input(\"Question:\")\n",
    "prompt_part_two = f\"\"\"\n",
    "To use a tool you should write Action: and tool you want to use\n",
    "{prompt_part_one}\n",
    "User: Hello how are you?\n",
    "Bot: I am doing well, thank you for asking. How can I assist you today?\n",
    "User: {inp}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt_part_two)\n",
    "\n",
    "out = Model_selector(model, prompt_part_two)\n",
    "print(out)\n",
    "out = between_LLM_and_user(out, inp, model)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = between_LLM_and_user(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7015a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "  @media print {\n",
      "    .ms-editor-squiggles-container {\n",
      "      display:none !important;\n",
      "    }\n",
      "  }\n",
      "  .ms-editor-squiggles-container {\n",
      "    all: initial;\n",
      "  }when was chatgpt 4 released\n",
      "\n",
      "To use a tool you should write Action: and tool you want to use\n",
      "\n",
      "Here are the tools you can use to calculate or collect information from the internet or python code to execute or voice reply, If you need: \n",
      "Calculator[<Your expression to calculate>], Search[<Key words to search in internet>], Python[```python <Your python code here> ```], Voice[<Your text>]\n",
      "Example of Actions:\n",
      "Action: Calculator[12*34-57]\n",
      "Action: Search[All the influencers of HELIOS Company]\n",
      "Action: Python[```python\n",
      "a = 12\n",
      "b = 10\n",
      "c = a+b\n",
      "print(c) ```]\n",
      "\n",
      "\n",
      "User: Hello how are you?\n",
      "Bot: I am doing well, thank you for asking. How can I assist you today?\n",
      "User: when was chatgpt 4 released\n",
      "\n",
      "Action: Search[When was chatgpt 4 released]\n",
      "Action Tools using:  ['Search[When was chatgpt 4 released]']\n",
      "Query sending to tools handler when was chatgpt 4 released\n",
      "When was chatgpt 4 released\n",
      "**Summary of Reference:**\n",
      "\n",
      "GPT-4, an advanced language model, was released on March 14, 2023. It surpasses ChatGPT in reasoning capabilities and can handle larger text inputs, up to 25,000 words. GPT-4 is available for premium ChatGPT Plus subscribers.\n",
      "\n",
      "**Connection to the Question:**\n",
      "\n",
      "The provided reference includes information about the release date of GPT-4, which aligns with the question asking when it was released.\n",
      "\n",
      "**Answer to the Question:**\n",
      "\n",
      "GPT-4 was released on March 14, 2023.\n"
     ]
    }
   ],
   "source": [
    "#Hi, what is the name of the Claus opus creator? i just want to know\n",
    "inp = input(\"Question:\")\n",
    "prompt_part_two = f\"\"\"\n",
    "To use a tool you should write Action: and tool you want to use\n",
    "{prompt_part_one}\n",
    "User: Hello how are you?\n",
    "Bot: I am doing well, thank you for asking. How can I assist you today?\n",
    "User: {inp}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(prompt_part_two)\n",
    "\n",
    "out = Model_selector(model, prompt_part_two)\n",
    "# print(out)\n",
    "out = between_LLM_and_user(out)\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_actions(text):\n",
    "    actions = []\n",
    "\n",
    "    action_pattern = r'Action \\d+:\\s*(.*)'\n",
    "\n",
    "    actions = re.findall(action_pattern, text)\n",
    "\n",
    "    return thoughts, actions, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ff5b1c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oice[Hello how are you?\n",
      "alculator[12*34-57\n",
      "earch[All the influencers of HELIOS Company\n",
      "ython[```pytho\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_actions(text):\n",
    "    print(\"text:\", text)\n",
    "    print(\"\")\n",
    "    pattern = r'[Aa]ction(?:[:\\s\\d]+)?\\s*([^\\[\\]]+\\[[^\\[\\]]+\\])'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n",
    "\n",
    "resp = \"\"\"Action: Python[```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'Product': ['iPhone', 'iPad', 'MacBook', 'Apple Watch'],\n",
    "        'Sales': [100, 200, 300, 400]}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df) ```]\"\"\"\n",
    "\n",
    "actions_list = extract_actions(out)\n",
    "print(\"Action Tools using: \",actions_list)\n",
    "actions_tools_dic = convert_list_to_dict(actions_list)\n",
    "main_dict = actions_tools_dic\n",
    "last_key_value = {list(main_dict.keys())[-1]: main_dict[list(main_dict.keys())[-1]]}\n",
    "ans = handle_request(last_key_value, \"Hi, what is the name of the Claus opus creator? i just want to know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ff36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actions_list = extract_action(out)\n",
    "actions_tools_dic = convert_list_to_dict(actions_list)\n",
    "print(\"Action Tools Found: (List) \",actions_tools_dic)\n",
    "\n",
    "main_dict = actions_tools_dic\n",
    "last_key_value = {list(main_dict.keys())[-1]: main_dict[list(main_dict.keys())[-1]]}\n",
    "\n",
    "print(\"Last Key value: (Dictionary) \",last_key_value)\n",
    "result = handle_request(last_key_value, i)\n",
    "            \n",
    "ans = handle_request(out, \"Hi, what is the name of the Claus opus creator? i just want to know\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57365092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612d765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d54e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0aa89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825d6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_K",
   "language": "python",
   "name": "openai_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
